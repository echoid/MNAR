{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data_loaders import *\n",
    "\n",
    "from missing_process.missing_method import * \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"datasets/wine_quality_white/breast-cancer-wisconsin.data\",header=None)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "array = np.random.rand(10)\n",
    "miss_indices = np.random.choice(10, 2, replace=False)\n",
    "array[miss_indices] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5488135 ,  0.71518937, -4.        ,  0.54488318,  0.4236548 ,\n",
       "       -4.        ,  0.43758721,  0.891773  ,  0.96366276,  0.38344152])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "processed_data_path_norm = (\n",
    "            f\"datasets/wine_quality_white/missing_ratio-{0.2}_seed-{1}_max-min_norm.pk\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(processed_data_path_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Normalized dataset loaded--------\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(processed_data_path_norm):\n",
    "    with open(processed_data_path_norm, \"rb\") as f:\n",
    "                observed_values, observed_masks, gt_masks = pickle.load(\n",
    "                    f\n",
    "                )\n",
    "    print(\"--------Normalized dataset loaded--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 1, 0, 1],\n",
       "       [1, 0, 0, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/wine_quality_white/data.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "wget.download(url, out='datasets/wine_quality_white/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TabCSDI/data (1).csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv\"#\n",
    "\n",
    "wget.download(url,\"TabCSDI/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_NA(X, p_miss, mecha=\"OTselfmask\", p_obs=0.2, q=0.25):\n",
    "    \"\"\"\n",
    "    Generate missing values for specifics missing-data mechanism and proportion of missing values. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.DoubleTensor or np.ndarray, shape (n, d)\n",
    "        Data for which missing values will be simulated.\n",
    "        If a numpy array is provided, it will be converted to a pytorch tensor.\n",
    "    p_miss : float\n",
    "        Proportion of missing values to generate for variables which will have missing values.\n",
    "    mecha : str, \n",
    "            Indicates the missing-data mechanism to be used. \"MCAR\" by default, \"MAR\", \"MNAR\" or \"MNARsmask\"\n",
    "    opt: str, \n",
    "         For mecha = \"MNAR\", it indicates how the missing-data mechanism is generated: using a logistic regression (\"logistic\"), quantile censorship (\"quantile\") or logistic regression for generating a self-masked MNAR mechanism (\"selfmasked\").\n",
    "    p_obs : float\n",
    "            If mecha = \"MAR\", or mecha = \"MNAR\" with opt = \"logistic\" or \"quanti\", proportion of variables with *no* missing values that will be used for the logistic masking model.\n",
    "    q : float\n",
    "        If mecha = \"MNAR\" and opt = \"quanti\", quantile level at which the cuts should occur.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A dictionnary containing:\n",
    "    'X_init': the initial data matrix.\n",
    "    'X_incomp': the data with the generated missing values.\n",
    "    'mask': a matrix indexing the generated missing values.s\n",
    "    \"\"\"\n",
    "    \n",
    "    to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
    "    if not to_torch:\n",
    "        X = X.astype(np.float32)\n",
    "        X = torch.from_numpy(X)\n",
    "    \n",
    "    if mecha == \"MAR\":\n",
    "        print(\"MAR\")\n",
    "        mask = MAR_mask(X, p_miss, p_obs).double()\n",
    "\n",
    "    elif mecha == \"OTlogistic\":\n",
    "        print(\"OTlogistic\")\n",
    "        mask = MNAR_mask_logistic(X, p_miss, p_obs).double()\n",
    "\n",
    "    elif mecha == \"OTquantile\":\n",
    "        print(\"OTquantile\")\n",
    "        mask = MNAR_mask_quantiles(X, p_miss, q, 1-p_obs).double()\n",
    "\n",
    "    elif mecha == \"OTselfmask\":\n",
    "        print(\"OTselfmask\")\n",
    "        mask = MNAR_self_mask_logistic(X, p_miss).double()\n",
    "\n",
    "    else:\n",
    "        print(\"MCAR\")\n",
    "        mask = (torch.rand(X.shape) < p_miss).double()\n",
    "    \n",
    "    X_nas = X.clone()\n",
    "    X_nas[mask.bool()] = np.nan\n",
    "    \n",
    "    return {'X_init': X.double(), 'X_incomp': X_nas.double(), 'mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=scale(dataset_loader(\"wine_quality_white\")[\"data\"])\n",
    "\n",
    "\n",
    "to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
    "if not to_torch:\n",
    "    X = X.astype(np.float32)\n",
    "    X = torch.from_numpy(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4898 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  ...,  True,  True, False],\n",
       "        [False, False,  True,  ..., False, False,  True],\n",
       "        [False, False, False,  ...,  True, False,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False,  True, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False,  True, False]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_logisitc = MNAR_mask_logistic(X, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 1] [ 0  3  5  6  7  8  9 10]\n",
      "torch.Size([4898, 8]) torch.Size([4898, 8])\n",
      "torch.Size([4898, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  ...,  True, False,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [ True, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True, False, False,  ...,  True, False,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True, False,  True]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MNAR_mask_logistic(X, p, p_params =0.3, exclude_inputs=True):\n",
    "\n",
    "    n, d = X.shape\n",
    "\n",
    "\n",
    "    to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
    "    if not to_torch:\n",
    "        X = torch.from_numpy(X)\n",
    "\n",
    "    mask = torch.zeros(n, d).bool() if to_torch else np.zeros((n, d)).astype(bool)\n",
    "    # control SPlit\n",
    "    d_params = max(int(p_params * d), 1) if exclude_inputs else d ## number of variables used as inputs (at least 1)\n",
    "    d_na = d - d_params if exclude_inputs else d ## number of variables masked with the logistic model\n",
    "    idxs_params = np.random.choice(d, d_params, replace=False) if exclude_inputs else np.arange(d) # 任选三个parameter obs\n",
    "\n",
    "    idxs_nas = np.array([i for i in range(d) if i not in idxs_params]) if exclude_inputs else np.arange(d) # 剩下的 feature miss\n",
    "\n",
    "    coeffs = pick_coeffs(X, idxs_params, idxs_nas)\n",
    "    intercepts = fit_intercepts(X[:, idxs_params], coeffs, p)\n",
    "\n",
    "\n",
    "    ps = torch.sigmoid(X[:, idxs_params].mm(coeffs) + intercepts)\n",
    "    \n",
    "    ber = torch.rand(n, d_na)\n",
    "    print(idxs_params,idxs_nas)\n",
    "    print(ber.shape,ps.shape)\n",
    "    mask[:, idxs_nas] = ber < ps\n",
    "\n",
    "    print(mask.shape)\n",
    "\n",
    "    if exclude_inputs:\n",
    "        mask[:, idxs_params] = torch.rand(n, d_params) < p\n",
    "\n",
    "    return mask\n",
    "def pick_coeffs(X, idxs_obs=None, idxs_nas=None, self_mask=False):\n",
    "    n, d = X.shape\n",
    "    if self_mask:\n",
    "        coeffs = torch.randn(d)\n",
    "        Wx = X * coeffs\n",
    "        coeffs /= torch.std(Wx, 0)\n",
    "    else:\n",
    "        d_obs = len(idxs_obs)\n",
    "        d_na = len(idxs_nas)\n",
    "        coeffs = torch.randn(d_obs, d_na) #dimension\n",
    "        Wx = X[:, idxs_obs].mm(coeffs)\n",
    "        coeffs /= torch.std(Wx, 0, keepdim=True)\n",
    "    return coeffs\n",
    "\n",
    "MNAR_mask_logistic(X, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNAR_self_mask_logistic(X, p):\n",
    "\n",
    "    n, d = X.shape\n",
    "\n",
    "    to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
    "    if not to_torch:\n",
    "        X = torch.from_numpy(X)\n",
    "\n",
    "    ### Variables will have NA proportions that depend on those observed variables, through a logistic model\n",
    "    ### The parameters of this logistic model are random.\n",
    "\n",
    "    ### Pick coefficients so that W^Tx has unit variance (avoids shrinking)\n",
    "    coeffs = pick_coeffs(X, self_mask=True)\n",
    "    ### Pick the intercepts to have a desired amount of missing values\n",
    "    intercepts = fit_intercepts(X, coeffs, p, self_mask=True)\n",
    "\n",
    "    ps = torch.sigmoid(X * coeffs + intercepts)\n",
    "\n",
    "    ber = torch.rand(n, d) if to_torch else np.random.rand(n, d)\n",
    "    mask = ber < ps if to_torch else ber < ps.numpy()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pick_coeffs(X, self_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_intercepts(X, coeffs, p, self_mask=False):\n",
    "    if self_mask:\n",
    "        d = len(coeffs)\n",
    "        intercepts = torch.zeros(d)\n",
    "        for j in range(d):\n",
    "            def f(x):\n",
    "                return torch.sigmoid(X * coeffs[j] + x).mean().item() - p\n",
    "            intercepts[j] = optimize.bisect(f, -50, 50)\n",
    "    else:\n",
    "        d_obs, d_na = coeffs.shape\n",
    "        intercepts = torch.zeros(d_na)\n",
    "        for j in range(d_na):\n",
    "            def f(x):\n",
    "                return torch.sigmoid(X.mv(coeffs[:, j]) + x).mean().item() - p\n",
    "            intercepts[j] = optimize.bisect(f, -50, 50)\n",
    "    return intercepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = len(coeffs)\n",
    "intercepts = torch.zeros(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4000,  0.7000,  0.0000,  ...,  3.5100,  0.5600,  9.4000],\n",
       "        [ 7.8000,  0.8800,  0.0000,  ...,  3.2000,  0.6800,  9.8000],\n",
       "        [ 7.8000,  0.7600,  0.0400,  ...,  3.2600,  0.6500,  9.8000],\n",
       "        ...,\n",
       "        [ 6.3000,  0.5100,  0.1300,  ...,  3.4200,  0.7500, 11.0000],\n",
       "        [ 5.9000,  0.6450,  0.1200,  ...,  3.5700,  0.7100, 10.2000],\n",
       "        [ 6.0000,  0.3100,  0.4700,  ...,  3.3900,  0.6600, 11.0000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
