{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data_loaders import *\n",
    "import missing_process.missing_method as missing_method\n",
    "from missing_process.block_rules import *\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(observed_values,seed):\n",
    "\n",
    "    N, D = observed_values.shape\n",
    "\n",
    "    dl = D - 1\n",
    "    \n",
    "    indlist = np.arange(N)\n",
    "\n",
    "    np.random.seed(seed + 1)\n",
    "    np.random.shuffle(indlist)\n",
    "\n",
    "    tmp_ratio = 1 / 5\n",
    "    start = (int)((5 - 1) * N * tmp_ratio)\n",
    "    \n",
    "    end = (int)(5 * N * tmp_ratio)\n",
    "\n",
    "    test_index = indlist[start:end]\n",
    "    remain_index = np.delete(indlist, np.arange(start, end))\n",
    "\n",
    "    np.random.shuffle(remain_index)\n",
    "\n",
    "    # Modify here to change train,valid ratio\n",
    "    num_train = (int)(len(remain_index) * 0.9)\n",
    "    train_index = remain_index[:num_train]\n",
    "    valid_index = remain_index[num_train:]\n",
    "\n",
    "    return train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Rule 0.25\n",
      "0 的占比: 11.421911421911423%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15354315966112275]\n",
      "Current Rule 0.5\n",
      "0 的占比: 23.696628574677355%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15354315966112275, 0.14056792539125404]\n",
      "Current Rule 0.75\n",
      "0 的占比: 34.58980044345898%\n",
      "[0.15354315966112275, 0.14056792539125404, 0.13030045179665234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataname = \"banknote\"#,,\n",
    "dataname = \"concrete_compression\"\n",
    "#dataname = \"wine_quality_white\"\n",
    "dataname = \"wine_quality_red\"\n",
    "seed = 1\n",
    "nfold = 5\n",
    "#missingtype = \"logistic\"\n",
    "missingtype = \"diffuse\"\n",
    "#missingtype = \"self_mask\"\n",
    "\n",
    "missing_rule = load_json_file(\"diffuse_ratio.json\")\n",
    "#missing_rule = load_json_file(\"q_ratio.json\")\n",
    "\n",
    "rule_list = []\n",
    "mean_list = []\n",
    "mice_list = []\n",
    "knn_list = []\n",
    "missforest_list = []\n",
    "\n",
    "\n",
    "for rule_name in missing_rule:\n",
    "    rule = missing_rule[rule_name]\n",
    "    print(\"Current Rule\",rule_name)\n",
    "    # Create folder\n",
    "    # Every loader contains \"observed_data\", \"observed_mask\", \"gt_mask\", \"timepoints\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dataset_path = f\"datasets/{dataname}/data.csv\"\n",
    "    processed_data_path = (\n",
    "        f\"datasets/{dataname}/{missingtype}-{rule_name}_seed-{seed}.pk\"\n",
    "    )\n",
    "    processed_data_path_norm = (\n",
    "        f\"datasets/{dataname}/{missingtype}-{rule_name}_seed-{seed}_max-min_norm.pk\"\n",
    "    )\n",
    "\n",
    "    if os.path.isfile(processed_data_path_norm):\n",
    "        with open(processed_data_path_norm, \"rb\") as f:\n",
    "            observed_values, observed_masks, gt_masks, eval_length = pickle.load(\n",
    "                f\n",
    "            )\n",
    "    else:\n",
    "        print(\"no data\")\n",
    "        break\n",
    "\n",
    "    # Calculate the percentage of zeros\n",
    "    zero_percentage = (gt_masks == 0).mean() * 100\n",
    "\n",
    "    print(f\"0 的占比: {zero_percentage}%\")\n",
    "\n",
    "    train_idx, test_idx = load_index(observed_values,seed)\n",
    "    \n",
    "#     # print(\"train_index\",len(train_idx))\n",
    "#     # print(\"test_index\",len(test_idx))\n",
    "\n",
    "\n",
    "    Xtrain = observed_values[train_idx]\n",
    "    Xtest = observed_values[test_idx]\n",
    "\n",
    "\n",
    "    Xtrain_mask = gt_masks[train_idx]\n",
    "    Xtest_mask = gt_masks[test_idx]\n",
    "\n",
    "    zero_percentage_train = (Xtrain_mask == 0).mean() * 100\n",
    "    zero_percentage_test = (Xtest_mask == 0).mean() * 100\n",
    "\n",
    "    Xnan = Xtrain.copy()\n",
    "    Xz = Xtrain.copy()\n",
    "    Xnan[Xtrain_mask == 0] = np.nan\n",
    "    Xz[Xtrain_mask == 0] = 0\n",
    "    \n",
    "    \n",
    "    X_test_nan = Xtest.copy()\n",
    "    X_test_z = Xtest.copy()\n",
    "    X_test_nan[Xtest_mask == 0] = np.nan\n",
    "    X_test_z[Xtest_mask == 0] = 0\n",
    "   \n",
    "    mean, Ximp = mean_imputer(Xnan,X_test_nan,Xtest,Xtest_mask)\n",
    "    pd.DataFrame(Ximp).to_csv(\"results/baselines/Imputation_{}_{}_{}.csv\".format(dataname,missingtype,rule_name),index=False)\n",
    "    mice, Ximp = mice_imputer(Xnan,X_test_nan,Xtest,Xtest_mask)\n",
    "    pd.DataFrame(Ximp).to_csv(\"results/baselines/Imputation_{}_{}_{}.csv\".format(dataname,missingtype,rule_name),index=False)\n",
    "    knn, Ximp = knn_imputer(Xnan,X_test_nan,Xtest,Xtest_mask)\n",
    "    pd.DataFrame(Ximp).to_csv(\"results/baselines/Imputation_{}_{}_{}.csv\".format(dataname,missingtype,rule_name),index=False)\n",
    "    missforest, Ximp = missforest_imputer(Xnan,X_test_nan,Xtest,Xtest_mask)\n",
    "    pd.DataFrame(Ximp).to_csv(\"results/baselines/Imputation_{}_{}_{}.csv\".format(dataname,missingtype,rule_name),index=False)\n",
    "    \n",
    "    rule_list.append(rule_name)\n",
    "    mean_list.append(mean)\n",
    "    mice_list.append(mice)\n",
    "    knn_list.append(knn)\n",
    "    missforest_list.append(missforest)\n",
    "\n",
    "    print(mean_list)\n",
    "\n",
    "result = pd.DataFrame({\"Missing_Rule\":rule_list,\"Mean\":mean_list,\"Mice\":mice_list,\"Missforest\":missforest_list,\"KNN\":knn_list})\n",
    "result.to_csv(\"results/baselines/RMSE_{}_{}.csv\".format(dataname,missingtype),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(train_nan,test_nan,test_real,test_mask):\n",
    "\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp.fit(train_nan)\n",
    "    Ximp = imp.transform(test_nan)\n",
    "    return np.sqrt(np.sum((test_real - Ximp) ** 2 * (1 - test_mask)) / np.sum(1 - test_mask)), Ximp\n",
    "\n",
    "def mice_imputer(train_nan,test_nan,test_real,test_mask):\n",
    "\n",
    "    imp = IterativeImputer(random_state=0, sample_posterior=True)\n",
    "    imp.fit(train_nan)\n",
    "    Ximp = imp.transform(test_nan)\n",
    "    return np.sqrt(np.sum((test_real - Ximp) ** 2 * (1 - test_mask)) / np.sum(1 - test_mask)), Ximp\n",
    "\n",
    "\n",
    "def knn_imputer(train_nan,test_nan,test_real,test_mask):\n",
    "\n",
    "    imp = KNNImputer(n_neighbors=2)\n",
    "    imp.fit(train_nan)\n",
    "    Ximp = imp.transform(test_nan)\n",
    "    return np.sqrt(np.sum((test_real - Ximp) ** 2 * (1 - test_mask)) / np.sum(1 - test_mask)), Ximp\n",
    "\n",
    "\n",
    "def missforest_imputer(train_nan,test_nan,test_real,test_mask):\n",
    "    impute_estimator = ExtraTreesRegressor(n_estimators=10, random_state=0)\n",
    "\n",
    "    imp = IterativeImputer(random_state=0, estimator=impute_estimator)\n",
    "    imp.fit(train_nan)\n",
    "    Ximp = imp.transform(test_nan)\n",
    "    return np.sqrt(np.sum((test_real - Ximp) ** 2 * (1 - test_mask)) / np.sum(1 - test_mask)), Ximp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
